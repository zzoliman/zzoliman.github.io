<1과목> 빅데이터 개요
1. 빅데이터
    1) 데이터 
        - 가역(이력추적가능)/불가역(원본환원불가)
        - 노나카 지식창조매커니즘 (공표연내) : 공통화(공유)/표출화(형식지)/연결화(체계화)/내면화(개인)
        - 지식의 피라미드(DIKW) : 데이터(100원)/정보(더 저렴)/지식(사야겠다)/지혜(다른것도)
        - 정보의특징 : 3정1관(정확성, 적절성, 적시성, 관련성)
    2) 빅데이터
        - 3V(용량,다양,속도)+2V(품질,가치)
        - 활용 3요소 : 자원, 기술, 인력(분석+IT+비즈니스)
        - 조직 : 집중형(별도전담조직,우선순위,이원화)/분산형(현업에 빠르게 적용)
          - 준비-성숙 4분면(정확준도) : 정착, 확산, 준비, 도입
        - 진화 : 처리 - 통합- 분석 - 연결 - 권리(마이데이터) 
        - 새로운 아이디어 제공 : 서비스 아닌 현업에서 도출
    3) 제도
        - 데이터3법 : 개인정보보호법+망+신용 / 개인정보 판단기준 명확화 / (가명정보/익명화)
        - 비식별화 : 사전-비식별(가명/범주/삭제/총계/마스킹)-적정성(k익명성/t근접성/l다양성)-사후

2. 빅데이터 분석 기획
    1) 과제발굴 방법론
        - 대상-방식 4분면 : Optimization(둘다앎),I(대상모름,방법앎),S,Discovery(둘다모름)
        - 과제 우선순위(시급성-난이도) 4분면 : 1,2,3,4(3 > 시급성4, 난이도1 > 2)
        - 하향식 : 문제->방안 / 탐색 - 정의 - 방안 - 평가
        - 상향식 : 데이터->문제 / 
        - 혼합식 : 수렴과 발산 반복 
        - ROI 투자비용 요소 : 크기, 형태, 속도 <-> 비즈니스 효과 : 가치
        - 목표시점 분류 : 단기(Quick-Win) / 중장기(문화내제화) / 혼합(빠르게 가치 조기 체험)

    2) 분석 방법론
        1) 계층적 프로세스(PTS) : 단계-태스크-스텝
        2) SW개발생명주기 
            - 폭포수 : 순차
            - 프로토타입 : MVP
            - 나선형 : 점진적(관리복잡)
            - 반복형 : 증분형(증분마다 설계,구현,운영 병행) / 진화형(완료 후 증분 개발, 릴리즈)
        3) KDD(Fayyad) : 선택(Selection) - 전처리 - 변환 - 마이닝 - 평가
        4) CRISP-DM : 업무이해-데이터이해-데이터준비-모델링-평가-전개(Deployee)
        5) SEMMA(SAS) : 추출(Sample)-탐색-수정-모델링-평가
        6) 빅데이터 분석방법론 5단계 : 기획(Planning)-준비-분석(데이터준비)-구현-평가 및 전개(모델발전계획 수립)

    3) 계획
        - 데이터 처리 프로세스 : 소스-수집-저장-처리- // -분석-표현
        - 작업분할구조(WBS) 수립 절차 : 비용 배분, 구조 수립, 업무 분장
        - 작업분할구조도 절차 : 과제 정의 - 준비와 탐색 - 모델링 및 검증 - *산출물 정리
        - 분석목표정의서 구성요소 : 원천데이터 조사, 방안 및 적용가능성, 평가
    
    4) 배포(전개) : 계획 - 보고서 작성 - 모니터링 - 리모델링(품질검토, 매개변수 최적화, 알고리즘 개선)


3. 빅데이터 기술(수집,저장,처리)
    1) 수집 
        - 수집시스템 구축 절차 : *유형파악 - *기술결정 - 아키텍처 - HW - 실행환경
        - 정형 품질기준(유유정일완) : 완전, 유일, 유효, 일관, 정확
        - 비정형 품질기준(이신사효기) : 기능, 신뢰, 사용, 효율, 이식

    2) 저장
        - 기능성(확장성, 일관성, 질의지원, 접근성) <-> *연계성(호환성)
        - NoSQL 분류
            - Key-Value : Redis(RDBMS보다 확장성 뛰어남)
            - 컬럼지향 : Cassnadra, HBase
            - 문서 : Mongo, Couch(Restful API, 웹강점)
    
    3) 처리
        - ETL - ODS(다양한 추출) - CDC(실시간ETL) 
        - OLTP(DB,트랜잭션,정규)/OLAP(DW,분석,비정규)
        - DW : 모델, ETL(추출+변환+적재/수집기술), ODS, OLAP
        - 데이터레이크 : 하둡
        - 맵리듀스 : 입력-분할-MAP-SHUFFLE-파티션-REDUCE

<2과목> 탐색과 통계
1. 전처리
    - 명(성별)서(설문점수)등(온도)비(키) 
    - 횡적자료(시간x) / 종적자료(시계열+횡적)
    1) 정제
        1) 결측값
            - MCAR(완전무작위) : 다른 변수와 무관(ex.데이터누락)
            - MAR(무작위) : 다른 변수 연관 + 비관측값 무관(ex.여성 체중 미응답)
            - NMAR(비무작위) : 결측이유(종속변수)와 연관(ex.뚱뚱한 사람 미응답)
            - 단순대치법 : 삭제 / 평균(표준오차 과소추정됨) / 회귀(조건부 평균 대치) / 
              단순확률(확률추출 무작위 대치) / 최근방(결측값 바로 이전값)
            - 다중대치법 : 대치 - 분석 - 결합
        2) 이상값
            - 원인 : 입력실수 / 측정오류 / 실험오류 / 의도적(남성 키) / 처리오류(전처리) / 표본오류(샘플링 편향)
            - 탐지 :
                1) 시각화(비모수,단변량) : box-plot, 줄기-잎 그림, 산점도
                2) Z-Score(모수,저변량) : 정규화(68%,95%,99%)
                3) DBSCAN(밀도기반 클러스터링) : 군집에서 먼 거리
                4) 고립 의사나무 : node 길이로 판단

    2) 변수처리(피처엔지니어링)
        1) 변수선택 
            - 전진선택법 : 영모형 + F검정 통계량(종속변수와의 상관계수)이 가장 큰 변수부터 추가
            - 후진선택법 : 전체모델 + 상관계수 가장 작은 변수 제거 + F 유의하지 않으면 제거
            - 단계적선택법 : 전진 + 후진
        2) 차원축소 
            - 필요성(해복과) : 해석력, 복잡도, 과적합
            1) 요인분석 : 기술통계. 
            2) 주성분분석(PCA) : 선형연관성이 없는 저차원 특징 추출. 직교변환. 분포특성 최대한 보존. 상관->비상관. 스케일링 필수.
            3) SVD(특이값분해) : M=(직교행렬m*n)(대각행렬m*n)(직교행렬n*n)
                * 직교행렬 : 전치행렬=역행렬
                * 대각행렬 : 대각성분 제외 나머지 0
                * 몇개의 k(특이값)만으로도 유사 행렬을 만들 수 있다.
            4) NMF(행렬과 음수 미포함 행렬분해) : V=WH+U
                * 분해한 행렬 하나가 전체 대략 정보(해)를 제시한다.
        3) 파생변수
            1) 파생변수 : 대표성 띄어야 함. 총합, 평균, 표준점수, 영역별 난이도 등
            2) 요약변수 : 집계(aggregate), DM 기본변수, 재활용성 높음, (ex. 개수, 횟수 등)
        4) 변수변환
            1) 범주형변환 : 연속형을 범주형으로 나누어 비교하면 설명이 효과적임.(상위10%)
            2) 정규화 : 만점 대비 / 최대최소([(X-min)/(max-min)]) / Z-점수([(X-평균)/분산])
               * 지수(좌측) - 제곱근(약간우측) - 로그(우측) - 역수(극단우측) : 선형, 정규분포 특성으로 변환 가능
               * 정규성검정 : 샤피로테스트, Q-Q Plot 
        5) 불균형 처리
            - 정확도가 높아도 재현율(TP/TP+FN)이 급격히 떨어짐
            1) 가중치 균형 : 고정비율(클래스 역비율을 가중치로), 최적비율(가중치 찾는 과정)
            2) 샘플링 : 언더샘플링(큰쪽을 일부만 선택), 오버샘플링(작은쪽을 큰쪽만큼 만듦)

2. EDA
    1) 상관분석 : 단순/다중/편
        1) 가정 : 독(독립표본,확률선정),선(선형성,산점도),등(Y퍼진정도일정),정(모집단 정규분포)
        2) 피어슨 상관계수 = (공분산)/(x표준편차 * y표준편차) = - +1 ~ -1 
            - 공분산 = 분(합(X편차*Y편차))
        3) 스피어만 상관계수 = 1 - ((6*합(x순위-y순위)^2)/(n*(n^2-1)))
            - 서열자료만 가능. 이상치 및 표본 작을 때 유용.
    2) 기초통계량
        1) 중심화 경향 : 산술(분합(x)) >= 기하(n루트(곱(x))=평균률), 중앙값(서수(n+1)/2), 최빈값, 분위수
        2) 분산도 경향 : 분산(분합(편차제곱), 특이점에 취약), 범위(최대-최소), 평균절대편차(MAD, 분합절대, 특이점 영향적음), 사분위편차(Q3-Q1), 변동계수(CV=표준편차/평균*100, 개인차)
        3) 비대칭도 : 왜도(치우침정도, 3제곱), 첨도(뾰족정도, 4제곱, 3이면 정규분포)
    3) 시각적 탐색 : 줄기-잎그림 : 십의자리 + 일의자리, 분포파악 가능 / IQR : Q3 - Q1(이상치 : +-1.5IQR 바깥)
    4) 시공간 탐색 : 유효시간 : 발생~소멸 시간 / 래스터 : 실세계 객체 / 위상적 타입 : 관계 
    5) 다변량 탐색
        1) 다중회귀 : 독립(설명)변수 2개 이상, 인과, 독선등정비 가정
        2) 로지스틱 회귀: 종속변수가 [0,1], 이진, 이상분포, 시그모이드
        3) 일원 분산분석(ANOVA) : 3개 이상 표본 "간, 내" 분산 비교, 독립변수 1개
        4) 다변량 분산분석(Multi ANOVA) : 이원 분산분석(독립변수 2개 이상) / ex.성별, 연령 -> 직무만족도
        5) 개체유도 : 유사성
            1) 군집 : 계층적(재분류 불가), 비계층적(재분류 가능), 조밀도(분포특성에 따라), 그래프(눈으로)
            2) 다차원척도법(MDS) : 거리(비유사성)으로 차원 축소, 주관적 해석 (ex. 차별화 방안 강구)
            3) 판별분석 : 분류에 영향 미치는 특성 측정

3. 통계기법
    1) 기술통계
        - 대표성 : 과잉대표(중복데이터 주도), 최소대표(이상치 주도) 
        1) 샘플링 : 단순무작위(사전지식없음), 계통(추출간격 N/K), 층화(집단간), 군집(집단내, 표본오차가능성)
        2) 확률 개요 : 사건(경우의수 부분집합) / 확률변수(경우의수 전체집합, 주사위눈 1~6) / 기대값 : 확률변수 결과값(f(x))의 평균
        3) 이산확률분포(베,이,기,다,포,초)
            - 베르누이(동전양면), 이항(N번 중 성공횟수 X), 다항(확률변수별 특정 횟수가 나타날 확률)
            - 포아송(단위시간내 몇번발생할지), 기하(첫성공까지 시도 횟수), 초기하(N개 중 원하는것 k개 뽑힐 확률)
        4) 연속확률분포(정,Z,카이제곱,t,F)
            - 정규(평균3배이상바깥버림), 표준정규(정규화=관측치-평균/표준편차=특정편차/전체편차)
            - 카이제곱(제곱합분포, 좌측치우침), t(정규분포평균측정, 뾰족종), F(두 확률변수가 카이제곱분포 따를 경우, 분산분석, 좌측+뾰족)
        5) 표본분포 : 중심극한정리(린데베르그-레비), 표준화=(관측치-평균)/(표준편차*제곱근(N))
    2) 추론통계
        1) 점추정
            - 모수 추정량 선택기준(불효일충) : 불편성(편향없음), 효율성(최소분산), 일치성(큰수법칙), 충분성(가장많은정보)
            - 적률(n개표본m개적률), 불편추정량(표본평균o,표본분산x), 최대우도추정(미분극대값활용)
        2) 구간추정 : 구간에 실제 모수가 있을 확률 구하기 (*표캡쳐)
            - 모평균(모분산 아는 경우) : 오른쪽 면적이 a/2인 표준정규분포Z(90%=1.645, 95%=1.96, 99%=2.576)
            - 모평균(모분산 모르는 경우+대표본) : Z분포(거의 상동)
            - 모평균(모분산 모르는 경우+소표본) : t분포(95%=1.725, 97.5%=2.086, 자유도가 크면 정규분포에 가까워짐)
            - 모분산 : 
            - 모비율 : 
        3) 가설검정 (*손그림)
            - p-value : 1종오류확률(무죄인데 유죄 = 귀무가설 참인데 기각) 나타나는 구간 ? 
            - 유의수준 = 기각역 = 모집단(귀무가설)과 불일치 구간 : p-value가 이 구간에 있으면 귀무가설 기각 (대립가설 채택) 
            - 신뢰수준 : p-value가 이 구간에 있으면 귀무가설 기각 불가(귀무가설 채택)
            - 임계치 = a값 : 경계선
        4) 표본검정 (*예제사진캡쳐, 손공식 - 204p)
            - 표본 평균검정(대표본 or 모집단 정규분포) : Z분포
            - 표본 평균검정(소표본) : t분포
            - 2개 독립표본 평균차이 검정 : T
            - 대응표본(처치전후) 평균차이 검정 : T

<3과목> - 모델링
1. 모형 설계
    - 모형 선정 절차(문수전모) : 문제정의 - 수집,도식화 - 전처리 - 모형선정
      * 평가기준표 : 필요성, 시급성, 가능성(수집,구현), 효과, 확장성
    - 모형 구축 절차(시설) : *시나리오 - *설계 - 가설검정(유의수준-기각역-검정통계량 관측-의사결정)
    - 업리프트 모델링(단계적, A/B테스트 대조) / 시각화(인과관계, GIS)

2. 모형 진단
    1) 정규성 검정
        - 샤피로-윌크스 : 표본수 2천개 미만
        - 콜모고로브-스미노브 : 표본수 2천개 초과
        - Q-Q Plot : 표본수 소규모, 눈으로
    2) 잔차 진단
        - 정규성(Q-Q Plot), 등분산성, 독립성(더빈-왓슨, 독립아니면 시계열회귀분석)

3. 분석 기법(모델)
    1) 회귀 분석
        - 가정(독선등정비) : 독립성(잔차독립,더빈왓슨), 선형성, 등분산성(잔차분산일정,산점도), 정규성(잔차기대값0), 다중공산성(변수상관관계없음,회귀분석)
    2) 범주형 분석(* 259p 표)
        - 분할표(차원:변수개수, 수준:범주개수) / 빈도분석(질적자료 오류 있는지) / 로지스틱(연속->이산 / *표캡쳐, 손공식 - 232p) 
        - 카이제곱검정(이산->이산 / 서로 상관있는지 독립인지) / T분포(이산->연속 / 집단 간 평균비교) / 분산분석(이산-> 연속 / 집단 간 분산비교?)
    3) 다변량 분석
        - 다중회귀분석(N->1) : (ex.가정소득+가족수 => 외식비)
        - 정준상관분석(N:1) : 변수축약, 인과 없음, 상관관계가 최대가 되도록 구성, (ex.외식동기 => 레스토랑선택)
        - 다변량분산분석(ANOVA, N->M) : (ex.관광집단 만족도 비교)
        - 다변량공분산분석(ANCOVA) : 종속변수들의 효과 제거 (ex. 학력통제 상태에서, 교육에 따른 성적 조사)
        - 다중판별분석 : 종속변수가 비계량적
    4) 시계열 분석
        - 불규칙 성분 / 체계적 성분 : 추세(지속), 계절(주기), 순환(긴주기), 복합(추세+계절)
        - 정상성 : 평균과 분산이 일정, 공분산 동일, 평균회귀경향 / 평균은 차분으로 일정하게 / 분산은 변환으로 일정하게 / 공분산 시차에만 의존 / 
        1) 단순 : 이동평균법(이평선), 지수평활법(최근에 가중치, 중장기예측), 분해법(체계적성분 분리, 계절조정)
        2) 모형 : 자귀회귀(AR, 어느정도의 과거 이용할지), 자기회귀이동평균(ARMA, MA에 잡음추가), 자기회귀누적이동평균(ARIMA, 비정상성, 차분하면 ARMA됨)
    5) 베이즈 기법(*손수식 269p)
        - 사전확률 + 추가정보 => 사후확률 / 주관적 믿음 정도 / 
        - 나이브베이즈(피처 독립 가정, ex.귤->노란색,둥글다,표면울퉁불퉁->독립, 가우시안/다항분포/베르누이)
    6) 의사결정나무(*예제캡쳐 - 235p, 표-237)
        - 깊이(가지 개수) / 분리기준(순수도 증가+불확실성 감소=정보획득) / 정지규칙(분리끝규칙)
        - p-value : 카이제곱, 유의수준 0.05보다 작을 경우 순수도가 낮음
        - 가지치기 : 에러감소(오류가 줄어들지 않을때까지), 롤포스트(정확도가 낮은 순서로 제거)
        - 분류나무 : 지니지수(불순도 측정), 엔트로피 지수(확신도 측정=불확실성, 0될때까지)
        - 회귀나무 : 분산분석 F통계량의 p값(등분산성 검정 p값커지면 순수도 높아짐), 분산감소량
        - 알고리즘 : 
    7) 신경망
        - ANN 초기 문제점 : HW속도, 초기값, 과적합 / 라벨링(셀프트레이닝) / 
        - 손실함수 : MSE(평균제곱오차-회귀) / CEE(교차엔트로피-분류)
        - 알고리즘 : 미니배치 - 경사하강법(미분으로 기울기산출) - 가중치갱신
        - 오차역전파(연쇄법칙) / 활성화함수 
        - CNN : 합성곱+풀링(최대,평균=> 속도효율,과적합)+완전연결 / 필터(윈도우) / 스트라이드(이동) / 패딩 / 입력채널수=필터채널수
        - RNN(순환모델, BPTT역전파, 필기체인식) / LSTM(망각게이트, Cell장기기억)
        - 오토인코더 : GAN과 달리 항상 동일결과 / 디노이징(입력손실제거), 희소(일부노드만학습), VAE(확률분포 학습)
        - GAN : 판별자 결과로 생성자 가중치 학습 / DCGAN(한쪽 역량 치우침 개선)
    8) SVM
        - 초평면 : 마진이 가장 큰 폭을 가진 경계 찾기 / 서포트벡터(각 클래스 최전선, 초평면을 서포트) / 가중치벡터(초평면에 직교)
        - 커널트릭 : 고차원으로 사상하여 비선형 해결
    9) 연관성 분석(*문제-257p 27번)
        - 장바구니 분석(두 사건 관련성) / Apriori(최소지지도 이상의 빈발만, 가지치기)
        - 지지도(구입할 확률) / 신뢰도(조건부) / 향상도(독립인지)
    10) 군집 분석
        1) 척도 : 유클리드(L2), 맨하탄(L1), 민코우스키(4차원적 다양체, m=1,2), 마할라노비스(공분산행렬, 평균에서 얼마나 멀리), 자카드(비유사성)
        2) 계층적(상하위) : 최단, 최장, 평균, Ward(와드, 편차제곱합) / 덴드로그램(결합순서 트리)
        3) 비계층적(분할) : K-mean(k중심개수 선정), DBSCAN(밀도계산, 최소개체수), 확률분포기반(가우시안 믹스처, 정규분포 가정, 대용량에 비적합)
    11) 비정형 분석
        1) 데이터마이닝 : 통계진영(검정,모형) + DB(OLAP) + 인공지능(신경망, SOM) / ex.장바구니 분석, 신용평가모형 등
        2) 텍스트마이닝 / 자연어처리(언어연구+인지과학)
        3) 오피니언 : 감정분석(의견,평가) / ex.입소문 분석
        4) 웹마이닝 : 로그, 행동, CRM(고객관계관리)와 연동, 링크구조
        5) 리얼리티마이닝 : 스마트폰, 센서, 행동모델링, 라이프 로그
    12) 앙상블 분석 : 보팅(다수결+평균+다른모델간), 배깅(다수결+평균+같은모델간/부트스트래핑(복원임의추출법)/랜덤포레스트), 부스팅(약->강분류기, 가중치갱신, 오래걸림), 앙상블(다수결+평균아님)
    13) 비모수 통계 : 모집단과 관계없이 / 명,서 / 질적척도 / 
        - 부호검정(맞다,아니다) / 윌콕슨(순위) / 만위트니(두 집단간 중심위치 비교) / 크루스칼-왈리스(3개이상 중앙값 차이 검정)

<4과목>
1. 평가
    1) 분류 평가지표(290p)
    2) 회귀 평가지표(*손공식)
        1) SSE
        2) MSE
        3) MAE
        4) 결정계수 : 회귀식이 변동을 얼마나 잘 설명하는지
        5) 수정 결정계수
        6) AIC : 낮을수록 적합도가 높아짐
        7) BIC : 변수 개수가 많을수록 AIC보다 패널티 증가
    3) 비지도-군집 평가지표 
        1) 실루엣 계수 : 같은 군집 내 거리 평균, 0.5 이상이면 적절한 군집
        2) Dunn Index : 군집 "간" 거리 멀수록, 군집 "내" 분산 작을수록 
    4) 적합도 검정 : 가정한 확률에 얼마나 맞는지
        1) 카이제곱검정 (독립인지 상관인지) * 295p예제
        2) 콜모고로프 스미르노프 검정(K-S Test) : 누적분포함수 차이 활용 * 296p 예제
    5) 비즈니스 : ROI, 효율성향상지표 등
    6) 시각화 해석 : 회귀(산점도, 히트맵), 분류(산점도, 평행좌표계, 의사결정나무), 딥러닝(산포도,노드링크), 군집(산점도), 연관(네트워크그래프)

2. 개선
    1) 과적합 방지 : 데이터 분할(tvt), 데이터 양, K-fold교차검증, 정규화, 가중치 패널티로 감소(L2규제-릿지,L1규제-라쏘), 드롭아웃(삭제비율을 출력에 곱함), 하이퍼파라미터 최적화, 풀링, 편향-분산 트레이드오프
    2) 학습방법 최적화
        - SGD : 확률적으로 랜덤 선택값에 대해서만 기울기 계산, 대신 지그재그 비효율
        - 모멘텀 : SGD+가속도=누적된 기울기 값으로 빠른 최적점 수렴 가능, 공구르듯
        - AdaGrad : 처음엔 크게 학습, 최적점에 가까울수록 작게 학습, 좌우흔들림 덜함
        - Adam : 모멘텀+AdaGrad
    3) 하이퍼파라미터 최적화 : 미니배치크기, 에폭수, 학습율, 규제강도, 은닉층 수

3. 시각화
    - 속성 : 위치, 형태(연속형 적용불가), 크기, 색, 선(굵기, 유형)
    1) 유사개념
        1) 데이터 시각화 : 텍스트, 지형, 관계 등도 포함
        2) 시각적 분석 : 데이터 시각화 부분집합으로 상호작용, 인터페이스 포함
        3) 정보 디자인 : 디자인(공공표지판)
        4) 인포 그래픽 : 정보와 지식을 한 눈에(나폴레옹 원정지도)
    2) 시간(한 축이 시간) : *막대(누적,묶은 포함
    <->히스토그램), *점, 꺾은선, 계단, 추세선
    3) 분포(%) : 히스토그램(한 축이 구간, 구간폭에 따라 착시 유의), 원(크기 직관적, 상세값은 모름), 도넛(길이), 트리맵(크기활용,계층적<->히트맵(관계,비교)), 누적연속(경향성<->누적막대(시간),평행좌표계(비교))
    4) 관계(추세선) : 산점도(3차원도가능,상관o,인과x), 버블차트(산점도에서 점이 원으로 커짐, 관계,공간), 히트맵(관계,비교)
    5) 비교 : 히트맵(관계,비교), 체르노프페이스(색x), 스타차트, 평행좌표계, *다차원척도법(MDS, 유사성)
    6) 공간(지도) : 단계구분도(서울시 구별 인구밀도 색), 카토그램(인위적 왜곡, 국가별 인구밀도), 버블차트


<일정>
*이기적 단권화 정리 - 수
*이지패스 요약 + 사진 + 그림 처리 - 수
이지패스 단권화 합치기 - 목
손공식 옮기기 - 금
주말 문제풀이 오답 단권화 반영 - 금
ADP문제풀이집 오답 단권화 반영 - 금